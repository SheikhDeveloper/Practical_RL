{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REINFORCE in PyTorch\n",
    "\n",
    "Just like we did before for Q-learning, this time we'll design a PyTorch network to learn `CartPole-v0` via policy gradient (REINFORCE).\n",
    "\n",
    "Most of the code in this notebook is taken from approximate Q-learning, so you'll find it more or less familiar and even simpler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "if 'google.colab' in sys.modules and not os.path.exists('.setup_complete'):\n",
    "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/setup_colab.sh -O- | bash\n",
    "    !pip install -q gymnasium\n",
    "    !pip install moviepy\n",
    "    !apt install ffmpeg\n",
    "    !pip install imageio-ffmpeg\n",
    "    !touch .setup_complete\n",
    "\n",
    "# This code creates a virtual display to draw game images on.\n",
    "# It will have no effect if your machine has a monitor.\n",
    "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
    "    !bash ../xvfb start\n",
    "    os.environ['DISPLAY'] = ':1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also you need to install ffmpeg if not installed\n",
    "# for MacOS: ! brew install ffmpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A caveat: with some versions of `pyglet`, the following cell may crash with `NameError: name 'base' is not defined`. The corresponding bug report is [here](https://github.com/pyglet/pyglet/issues/134). If you see this error, try restarting the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0cad1cf770>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
    "\n",
    "# gym compatibility: unwrap TimeLimit\n",
    "if hasattr(env, '_max_episode_steps'):\n",
    "    env = env.env\n",
    "\n",
    "env.reset()\n",
    "n_actions = env.action_space.n\n",
    "state_dim = env.observation_space.shape\n",
    "\n",
    "plt.imshow(env.render())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the network for REINFORCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For REINFORCE algorithm, we'll need a model that predicts action probabilities given states.\n",
    "\n",
    "For numerical stability, please __do not include the softmax layer into your network architecture__.\n",
    "We'll use softmax or log-softmax where appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a simple neural network that predicts policy logits. \n",
    "# Keep it simple: CartPole isn't worth deep architectures.\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(state_dim[0], 256),\n",
    "    nn.ELU(),\n",
    "    nn.Linear(256, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, n_actions)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: output value of this function is not a torch tensor, it's a numpy array.\n",
    "So, here gradient calculation is not needed.\n",
    "<br>\n",
    "Use [no_grad](https://pytorch.org/docs/stable/autograd.html#torch.autograd.no_grad)\n",
    "to suppress gradient calculation.\n",
    "<br>\n",
    "Also, `.detach()` (or legacy `.data` property) can be used instead, but there is a difference:\n",
    "<br>\n",
    "With `.detach()` computational graph is built but then disconnected from a particular tensor,\n",
    "so `.detach()` should be used if that graph is needed for backprop via some other (not detached) tensor;\n",
    "<br>\n",
    "In contrast, no graph is built by any operation in `no_grad()` context, thus it's preferable here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_probs(states):\n",
    "    \"\"\" \n",
    "    Predict action probabilities given states.\n",
    "    :param states: numpy array of shape [batch, state_shape]\n",
    "    :returns: numpy array of shape [batch, n_actions]\n",
    "    \"\"\"\n",
    "    # convert states, compute logits, use softmax to get probability\n",
    "    with torch.no_grad():\n",
    "        preds = model(torch.tensor(states))\n",
    "    return F.softmax(preds, dim=1).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_states = np.array([env.reset()[0] for _ in range(5)])\n",
    "test_probas = predict_probs(test_states)\n",
    "assert isinstance(test_probas, np.ndarray), \\\n",
    "    \"you must return np array and not %s\" % type(test_probas)\n",
    "assert tuple(test_probas.shape) == (test_states.shape[0], env.action_space.n), \\\n",
    "    \"wrong output shape: %s\" % np.shape(test_probas)\n",
    "assert np.allclose(np.sum(test_probas, axis=1), 1), \"probabilities do not sum to 1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play the game\n",
    "\n",
    "We can now use our newly built agent to play the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_session(env, t_max=1000):\n",
    "    \"\"\"\n",
    "    Play a full session with REINFORCE agent.\n",
    "    Returns sequences of states, actions, and rewards.\n",
    "    \"\"\"\n",
    "    # arrays to record session\n",
    "    states, actions, rewards = [], [], []\n",
    "\n",
    "    s = env.reset()[0]\n",
    "\n",
    "    for t in range(t_max):\n",
    "        # action probabilities array aka pi(a|s)\n",
    "        action_probs = predict_probs(np.array([s]))[0]\n",
    "\n",
    "        # Sample action with given probabilities.\n",
    "        a = np.random.choice(env.action_space.n, p=action_probs)\n",
    "\n",
    "        new_s, r, terminated, truncated, info = env.step(a)\n",
    "\n",
    "        # record session history to train later\n",
    "        states.append(s)\n",
    "        actions.append(a)\n",
    "        rewards.append(r)\n",
    "\n",
    "        s = new_s\n",
    "        if terminated or truncated:\n",
    "            break\n",
    "\n",
    "    return states, actions, rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test it\n",
    "states, actions, rewards = generate_session(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing cumulative rewards\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "G_t &= r_t + \\gamma r_{t + 1} + \\gamma^2 r_{t + 2} + \\ldots \\\\\n",
    "&= \\sum_{i = t}^T \\gamma^{i - t} r_i \\\\\n",
    "&= r_t + \\gamma * G_{t + 1}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cumulative_rewards(rewards,  # rewards at each step\n",
    "                           gamma=0.99  # discount for reward\n",
    "                           ):\n",
    "    \"\"\"\n",
    "    Take a list of immediate rewards r(s,a) for the whole session \n",
    "    and compute cumulative returns (a.k.a. G(s,a) in Sutton '16).\n",
    "    \n",
    "    G_t = r_t + gamma*r_{t+1} + gamma^2*r_{t+2} + ...\n",
    "\n",
    "    A simple way to compute cumulative rewards is to iterate from the last\n",
    "    to the first timestep and compute G_t = r_t + gamma*G_{t+1} recurrently\n",
    "\n",
    "    You must return an array/list of cumulative rewards with as many elements as in the initial rewards.\n",
    "    \"\"\"\n",
    "    cummulative_rewards = [0.] * len(rewards)\n",
    "    cummulative_rewards[len(rewards) - 1] = rewards[-1]\n",
    "    for i in range(len(rewards) - 2, -1, -1):\n",
    "        cummulative_rewards[i] = rewards[i] + gamma * cummulative_rewards[i + 1]\n",
    "    return cummulative_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looks good!\n"
     ]
    }
   ],
   "source": [
    "get_cumulative_rewards(rewards)\n",
    "assert len(get_cumulative_rewards(list(range(100)))) == 100\n",
    "assert np.allclose(\n",
    "    get_cumulative_rewards([0, 0, 1, 0, 0, 1, 0], gamma=0.9),\n",
    "    [1.40049, 1.5561, 1.729, 0.81, 0.9, 1.0, 0.0])\n",
    "assert np.allclose(\n",
    "    get_cumulative_rewards([0, 0, 1, -2, 3, -4, 0], gamma=0.5),\n",
    "    [0.0625, 0.125, 0.25, -1.5, 1.0, -4.0, 0.0])\n",
    "assert np.allclose(\n",
    "    get_cumulative_rewards([0, 0, 1, 2, 3, 4, 0], gamma=0),\n",
    "    [0, 0, 1, 2, 3, 4, 0])\n",
    "print(\"looks good!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss function and updates\n",
    "\n",
    "We now need to define objective and update over policy gradient.\n",
    "\n",
    "Our objective function is\n",
    "\n",
    "$$ J \\approx  { 1 \\over N } \\sum_{s_i,a_i} G(s_i,a_i) $$\n",
    "\n",
    "REINFORCE defines a way to compute the gradient of the expected reward with respect to policy parameters. The formula is as follows:\n",
    "\n",
    "$$ \\nabla_\\theta \\hat J(\\theta) \\approx { 1 \\over N } \\sum_{s_i, a_i} \\nabla_\\theta \\log \\pi_\\theta (a_i \\mid s_i) \\cdot G_t(s_i, a_i) $$\n",
    "\n",
    "We can abuse PyTorch's capabilities for automatic differentiation by defining our objective function as follows:\n",
    "\n",
    "$$ \\hat J(\\theta) \\approx { 1 \\over N } \\sum_{s_i, a_i} \\log \\pi_\\theta (a_i \\mid s_i) \\cdot G_t(s_i, a_i) $$\n",
    "\n",
    "When you compute the gradient of that function with respect to network weights $\\theta$, it will become exactly the policy gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code: define optimizers\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-3)\n",
    "\n",
    "\n",
    "def train_on_session(states, actions, rewards, gamma=0.99, entropy_coef=1e-2):\n",
    "    \"\"\"\n",
    "    Takes a sequence of states, actions and rewards produced by generate_session.\n",
    "    Updates agent's weights by following the policy gradient above.\n",
    "    Please use Adam optimizer with default parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    # cast everything into torch tensors\n",
    "    states = torch.tensor(states, dtype=torch.float32)\n",
    "    actions = torch.tensor(actions, dtype=torch.int64)\n",
    "    cumulative_returns = np.array(get_cumulative_rewards(rewards, gamma))\n",
    "    cumulative_returns = torch.tensor(cumulative_returns, dtype=torch.float32)\n",
    "\n",
    "    # predict logits, probas and log-probas using an agent.\n",
    "    logits = model(states)\n",
    "    probs = nn.functional.softmax(logits, -1)\n",
    "    log_probs = nn.functional.log_softmax(logits, -1)\n",
    "\n",
    "    assert all(isinstance(v, torch.Tensor) for v in [logits, probs, log_probs]), \\\n",
    "        \"please use compute using torch tensors and don't use predict_probs function\"\n",
    "\n",
    "    # select log-probabilities for chosen actions, log pi(a_i|s_i)\n",
    "    log_probs_for_actions = torch.sum(\n",
    "        log_probs * F.one_hot(actions, env.action_space.n), dim=1)\n",
    "   \n",
    "    # Compute loss here. Don't forgen entropy regularization with `entropy_coef` \n",
    "    entropy = - torch.sum(log_probs * probs, dim=1).mean()\n",
    "    loss = -torch.mean(log_probs_for_actions * cumulative_returns) - entropy_coef * entropy\n",
    "\n",
    "    # Gradient descent step\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # technical: return session rewards to print them later\n",
    "    return np.sum(rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The actual training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean reward: 26.290\n",
      "mean reward: 20.750\n",
      "mean reward: 23.440\n",
      "mean reward: 28.400\n",
      "mean reward: 22.370\n",
      "mean reward: 30.990\n",
      "mean reward: 70.730\n",
      "mean reward: 194.350\n",
      "mean reward: 240.770\n",
      "mean reward: 502.930\n",
      "You Win!\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    rewards = [train_on_session(*generate_session(env)) for _ in range(100)]  # generate new sessions\n",
    "    \n",
    "    print(\"mean reward: %.3f\" % (np.mean(rewards)))\n",
    "    \n",
    "    if np.mean(rewards) > 500:\n",
    "        print(\"You Win!\")  # but you can train even further\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results & video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record sessions\n",
    "\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "\n",
    "with gym.make(\"CartPole-v1\", render_mode=\"rgb_array\") as env, RecordVideo(\n",
    "    env=env, video_folder=\"./videos\"\n",
    ") as env_monitor:\n",
    "    sessions = [generate_session(env_monitor) for _ in range(10)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"640\" height=\"480\" controls>\n",
       "  <source src=\"videos/rl-video-episode-8.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show video. This may not work in some setups. If it doesn't\n",
    "# work for you, you can download the videos and view them locally.\n",
    "\n",
    "from pathlib import Path\n",
    "from base64 import b64encode\n",
    "from IPython.display import HTML\n",
    "\n",
    "video_paths = sorted([s for s in Path('videos').iterdir() if s.suffix == '.mp4'])\n",
    "video_path = video_paths[-1]  # You can also try other indices\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    # https://stackoverflow.com/a/57378660/1214547\n",
    "    with video_path.open('rb') as fp:\n",
    "        mp4 = fp.read()\n",
    "    data_url = 'data:video/mp4;base64,' + b64encode(mp4).decode()\n",
    "else:\n",
    "    data_url = str(video_path)\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"{}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(data_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
